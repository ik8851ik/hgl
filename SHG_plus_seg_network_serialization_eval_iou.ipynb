{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorlayer as tl\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1# 한 iteration에 몇개의 batch를 사용할지\n",
    "image_resize_w = 256\n",
    "image_resize_h = 256\n",
    "nstack = 2  # num of hourglass stack\n",
    "\n",
    "net_ouput_w = 64\n",
    "net_ouput_h = 64\n",
    "\n",
    "save_freq = 20000 # model weights를 저장하는 주기\n",
    "save_dir = \"./model\"\n",
    "\n",
    "vis_test_dir = \"./vis/test\"\n",
    "\n",
    "path_pose_joint = \"/media/vision/Seagate Expansion Drive/coco2014data/original/test\" # 데이터셋의 경로\n",
    "\n",
    "test_imgs = os.listdir(path_pose_joint)\n",
    "test_imgs_num = int(len(test_imgs)/3)\n",
    "    \n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "if not os.path.exists(vis_test_dir):\n",
    "    os.makedirs(vis_test_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _data_aug_fn(image, joints_image, segs_image):\n",
    "    h = len(image)\n",
    "    w = len(image[0])\n",
    "\n",
    "    joint = np.zeros([net_ouput_h,net_ouput_w,18], dtype=np.float32)  # 17 + background\n",
    "    existing_joints = np.unique(joints_image)\n",
    "    \n",
    "    for existing_joint in existing_joints:\n",
    "        if existing_joint != 0:\n",
    "            tmp_y = np.where(joints_image == existing_joint)[0][0]\n",
    "            tmp_x = np.where(joints_image == existing_joint)[1][0]\n",
    "            resized_x = int(tmp_x/w * net_ouput_w)\n",
    "            resized_y = int(tmp_y/h * net_ouput_h)\n",
    "            joint[resized_y][resized_x][int(existing_joint/10)] = 1.0\n",
    "    \n",
    "    joint_bg = 1 - np.sum(joint[:,:,1:], axis=-1)\n",
    "    joint_bg[joint_bg < 0] = 0\n",
    "    joint[:,:,0] = joint_bg\n",
    "        \n",
    "    segs_image = np.squeeze(segs_image, axis=-1)\n",
    "    seg = np.eye(15,dtype=np.float32)[np.int32(segs_image/10)]\n",
    "    \n",
    "    \n",
    "    image = cv2.resize(image, (image_resize_h, image_resize_w))#, interpolation=cv2.INTER_NEAREST)\n",
    "    seg = cv2.resize(seg, (net_ouput_h, net_ouput_w), interpolation=cv2.INTER_NEAREST)\n",
    "    \n",
    "    return image, joint, seg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _map_fn(frame_name, joint_name, seg_name):\n",
    "    image = tf.image.decode_jpeg(tf.read_file(frame_name), channels=3)\n",
    "    joints_image = tf.image.decode_jpeg(tf.read_file(joint_name), channels=1)\n",
    "    segs_image = tf.image.decode_png(tf.read_file(seg_name), channels=1)\n",
    "     \n",
    "    img, joint, seg  = tf.py_func(_data_aug_fn, [image, joints_image, segs_image], [tf.uint8, tf.float32, tf.float32])\n",
    "    \n",
    "    img = tf.image.convert_image_dtype(img, dtype=tf.float32)\n",
    "    \n",
    "    \n",
    "    return img, joint, seg, image\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def densepose_agu(directory):\n",
    "    frame_name = []\n",
    "    joint_name = []\n",
    "    seg_name = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.jpg'):\n",
    "                tmp = []\n",
    "                frame_name.append(root + '/' + file)\n",
    "                joint_name.append(root + '/' + file[:-4] + '_keypoint.png')\n",
    "                seg_name.append(root + '/' + file[:-4] + '_seg.png')\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((frame_name, joint_name, seg_name))\n",
    "            \n",
    "    ds_test = dataset.map(_map_fn)\n",
    "\n",
    "    ds_test = ds_test.batch(batch_size)  \n",
    "    ds_test = ds_test.repeat()\n",
    "    return ds_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual(inputs, input_ch, ouput_ch, is_train):\n",
    "    if input_ch != ouput_ch:\n",
    "        identity = tf.layers.conv2d(inputs, ouput_ch, [1, 1], padding='same')#, activation=tf.nn.relu)\n",
    "        identity = tf.nn.relu(tf.layers.batch_normalization(identity, training=is_train))\n",
    "\n",
    "    else:\n",
    "        identity = inputs\n",
    "\n",
    "    net = tf.layers.conv2d(inputs, input_ch, [1, 1], padding='same')#, activation=tf.nn.relu)\n",
    "    net = tf.nn.relu(tf.layers.batch_normalization(net, training=is_train))\n",
    "\n",
    "    net = tf.layers.conv2d(net, input_ch, [3, 3], padding='same')#, activation=tf.nn.relu)\n",
    "    net = tf.nn.relu(tf.layers.batch_normalization(net, training=is_train))\n",
    "\n",
    "    net = tf.layers.conv2d(net, ouput_ch, [1, 1], padding='same')\n",
    "    net = tf.layers.batch_normalization(net, training=is_train)\n",
    "           \n",
    "    net += identity\n",
    "    return net\n",
    "\n",
    "def pre_hourglass(img, is_train):\n",
    "    save256 = residual(img, 3, 64, is_train) # 256 256 64\n",
    "    save256 = residual(save256, 64, 256, is_train) # 256 256 256\n",
    "    save256 = residual(save256, 256, 256, is_train) # 256 256 256\n",
    " \n",
    "    net = tf.layers.conv2d(img, 64, [7, 7], strides = 2, padding='same')#, activation=tf.nn.relu)\n",
    "    net = tf.nn.relu(tf.layers.batch_normalization(net, training=is_train))\n",
    "\n",
    "  #  print(\"128x128\")\n",
    "  #  print(net.shape)   #128 128 64\n",
    "    \n",
    "    net = residual(net, 64, 128, is_train)\n",
    "    \n",
    "    save128 = residual(net, 128, 256, is_train) # 128 128 64\n",
    "    save128 = residual(save128, 256, 256, is_train) # 128 128 256\n",
    "    save128 = residual(save128, 256, 256, is_train) # 128 128 256\n",
    "    \n",
    "    net = tf.layers.max_pooling2d(net, [2, 2], [2, 2])\n",
    "   # print(\"64x64\") \n",
    "   # print(net.shape) # 64 64 128\n",
    "    \n",
    "    net = residual(net, 128, 256, is_train) # 64 64 256\n",
    "    return net, save256, save128\n",
    "\n",
    "\n",
    "def post_hourglass(net, save256, save128, is_train):      ## input : 64 x 64 x 256\n",
    "    net = residual(net, 256, 256, is_train)\n",
    "    \n",
    "    net = tf.image.resize_nearest_neighbor(net, (128,128))\n",
    "    net += save128\n",
    "    \n",
    "    net = residual(net, 256, 256, is_train)\n",
    "    \n",
    "    net = tf.image.resize_nearest_neighbor(net, (256,256))\n",
    "    net += save256\n",
    "    \n",
    "    return net   \n",
    "    \n",
    "def hourglass(net, is_train):#, is_first = True):   ### input : 64 x 64 x 256\n",
    "    net = residual(net, 256, 256, is_train)\n",
    "    net = residual(net, 256, 256, is_train)\n",
    "\n",
    "    save64 = residual(net, 256, 256, is_train) # 64 64 256\n",
    "    save64 = residual(save64, 256, 256, is_train) # 64 64 256\n",
    "    save64 = residual(save64, 256, 256, is_train) # 64 64 256\n",
    "\n",
    "    \n",
    "    net = tf.layers.max_pooling2d(net, [2, 2], [2, 2]) # 32 32 256\n",
    "    net = residual(net, 256, 256, is_train)\n",
    "    net = residual(net, 256, 256, is_train)\n",
    "    net = residual(net, 256, 256, is_train)\n",
    "\n",
    "    save32 = residual(net, 256, 256, is_train) # 32 32 256\n",
    "    save32 = residual(save32, 256, 256, is_train) # 32 32 256\n",
    "    save32 = residual(save32, 256, 256, is_train) # 32 32 256\n",
    "\n",
    "    \n",
    "    net = tf.layers.max_pooling2d(net, [2, 2], [2, 2]) # 16 16 256\n",
    "    net = residual(net, 256, 256, is_train)\n",
    "    net = residual(net, 256, 256, is_train)\n",
    "    net = residual(net, 256, 256, is_train)\n",
    "\n",
    "    save16 = residual(net, 256, 256, is_train) # 16 16 256\n",
    "    save16 = residual(save16, 256, 256, is_train) # 16 16 256\n",
    "    save16 = residual(save16, 256, 256, is_train) # 16 16 256\n",
    "\n",
    "    \n",
    "    net = tf.layers.max_pooling2d(net, [2, 2], [2, 2]) # 8 8 256\n",
    "    net = residual(net, 256, 256, is_train)\n",
    "    net = residual(net, 256, 256, is_train)\n",
    "    net = residual(net, 256, 256, is_train)\n",
    "\n",
    "    \n",
    "    save8 = residual(net, 256, 256, is_train) # 8 8 256\n",
    "    save8 = residual(save8, 256, 256, is_train) # 8 8 256\n",
    "    save8 = residual(save8, 256, 256, is_train) # 8 8 256\n",
    "\n",
    "    \n",
    "    net = tf.layers.max_pooling2d(net, [2, 2], [2, 2]) # 4 4 256\n",
    "    \n",
    "    net = residual(net, 256, 256, is_train)\n",
    "    net = residual(net, 256, 256, is_train)\n",
    "    net = residual(net, 256, 256, is_train)\n",
    "    \n",
    "    \n",
    "    net = tf.image.resize_nearest_neighbor(net, (8,8))\n",
    "    net += save8\n",
    "    \n",
    "    net = residual(net, 256, 256, is_train)\n",
    "\n",
    "    \n",
    "    net = tf.image.resize_nearest_neighbor(net, (16,16))\n",
    "    net += save16\n",
    "    \n",
    "    net = residual(net, 256, 256, is_train)\n",
    "\n",
    "    \n",
    "    net = tf.image.resize_nearest_neighbor(net, (32,32))\n",
    "    net += save32\n",
    "\n",
    "    net = residual(net, 256, 256, is_train)\n",
    "\n",
    "    \n",
    "    net = tf.image.resize_nearest_neighbor(net, (64,64))\n",
    "    net += save64\n",
    "    \n",
    "    net = residual(net, 256, 256, is_train)\n",
    "    \n",
    "    inter_seg = tf.layers.conv2d(net, 15, [1, 1], padding='same')#, activation=tf.nn.relu)  ###input : 256 channel\n",
    "    interpredict_seg = tf.layers.batch_normalization(inter_seg, training=is_train)\n",
    "    \n",
    "    net = residual(interpredict_seg, 15, 128, is_train)\n",
    "    net = residual(net, 128, 256, is_train)\n",
    "    net += save64\n",
    "    \n",
    "    inter_key = tf.layers.conv2d(net, 18, [1, 1], padding='same')#, activation=tf.nn.relu)  ###input : 256 channel\n",
    "    interpredict_key = tf.layers.batch_normalization(inter_key, training=is_train)\n",
    "    \n",
    "    return net, interpredict_key, interpredict_seg   ## 64x64x256,  64x64x33\n",
    "#######################################################\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SHGnet(img, numstack, is_train): ##img = [batch, w, h, 3], hourglass-ing\n",
    "    with tf.variable_scope(\"SegNet\"):\n",
    "        net, save256, save128 = pre_hourglass(img, is_train)  ### 256 -> 64\n",
    "\n",
    "        interpredicts_key = []\n",
    "        interpredicts_seg = []\n",
    "        for i in range(numstack):\n",
    "            savenet = net\n",
    "            net, interpredict_key, interpredict_seg = hourglass(net, is_train)#, False)\n",
    "            interpredicts_key.append(interpredict_key)\n",
    "            interpredicts_seg.append(interpredict_seg)\n",
    "\n",
    "            inter_key = tf.layers.conv2d(interpredict_key, 256, [1, 1], padding='same')#, activation=tf.nn.relu)  ###input : 256 channel\n",
    "            inter_key = tf.nn.relu(tf.layers.batch_normalization(inter_key, training=is_train))\n",
    "            inter_seg = tf.layers.conv2d(interpredict_seg, 256, [1, 1], padding='same')#, activation=tf.nn.relu)  ###input : 256 channel\n",
    "            inter_seg = tf.nn.relu(tf.layers.batch_normalization(inter_seg, training=is_train))\n",
    "            \n",
    "            net += inter_key\n",
    "            net += inter_seg\n",
    "            net += savenet\n",
    "        \n",
    "\n",
    "        return interpredicts_key, interpredicts_seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_train(save_dir, input_image, joint_gt_index, seg_gt, joint_predict_index, seg_predict, step):   #batch result,img\n",
    "    image = input_image[0]\n",
    "    \n",
    "    h = len(image)\n",
    "    w = len(image[0])\n",
    "\n",
    "    seg_gt = seg_gt[0]\n",
    "    seg_pred = seg_predict[0]\n",
    "\n",
    "    image = cv2.flip(image, 0)\n",
    "    plt.clf()\n",
    "    implot = plt.imshow(image)    \n",
    "    for i in range(0,17):\n",
    "        if joint_gt_index[i][0] != 0 and joint_gt_index[i][1] != 0:\n",
    "            if i != 1 and i != 2 and i != 3 and i != 4:\n",
    "                plt.scatter(joint_gt_index[i][1]/64 * w, (64 - joint_gt_index[i][0])/64 * h, s = 4, color = 'blue', alpha = 0.8)\n",
    "                plt.scatter(joint_predict_index[i][1]/64 * w, (64 - joint_predict_index[i][0])/64 * h, s = 4, color = 'red', alpha = 0.8)\n",
    "    plt.xlim(0, w)\n",
    "    plt.ylim(0, h) \n",
    "#########################    \n",
    "    nose_x_gt = joint_gt_index[0][1]/64 * w\n",
    "    nose_y_gt = (64-joint_gt_index[0][0])/64 * h\n",
    "\n",
    "    left_shoulder_x_gt = joint_gt_index[5][1]/64 *w\n",
    "    left_shoulder_y_gt = (64-joint_gt_index[5][0])/64 * h\n",
    "    \n",
    "    right_shoulder_x_gt = joint_gt_index[6][1]/64 * w\n",
    "    right_shoulder_y_gt = (64-joint_gt_index[6][0])/64 * h\n",
    "    \n",
    "    neck_x_gt = (left_shoulder_x_gt + right_shoulder_x_gt)/2\n",
    "    neck_y_gt = (left_shoulder_y_gt + right_shoulder_y_gt)/2\n",
    "    \n",
    "    left_elbow_x_gt = joint_gt_index[7][1]/64 * w\n",
    "    left_elbow_y_gt = (64-joint_gt_index[7][0])/64 * h\n",
    "    \n",
    "    right_elbow_x_gt = joint_gt_index[8][1]/64 * w\n",
    "    right_elbow_y_gt = (64-joint_gt_index[8][0])/64 * h\n",
    "    \n",
    "    left_wrist_x_gt = joint_gt_index[9][1]/64 * w\n",
    "    left_wrist_y_gt = (64-joint_gt_index[9][0])/64 * h\n",
    "    \n",
    "    right_wrist_x_gt = joint_gt_index[10][1]/64 * w\n",
    "    right_wrist_y_gt = (64-joint_gt_index[10][0])/64 * h\n",
    "    \n",
    "    left_hip_x_gt = joint_gt_index[11][1]/64 * w\n",
    "    left_hip_y_gt = (64-joint_gt_index[11][0])/64 * h\n",
    "    \n",
    "    right_hip_x_gt = joint_gt_index[12][1]/64 * w\n",
    "    right_hip_y_gt = (64-joint_gt_index[12][0])/64 * h\n",
    "    \n",
    "    hip_x_gt = (left_hip_x_gt + right_hip_x_gt)/2\n",
    "    hip_y_gt = (left_hip_y_gt + right_hip_y_gt)/2\n",
    "\n",
    "    left_knee_x_gt = joint_gt_index[13][1]/64 * w\n",
    "    left_knee_y_gt = (64-joint_gt_index[13][0])/64 * h\n",
    "    \n",
    "    right_knee_x_gt = joint_gt_index[14][1]/64 * w\n",
    "    right_knee_y_gt = (64-joint_gt_index[14][0])/64 * h\n",
    "    \n",
    "    left_ankle_x_gt = joint_gt_index[15][1]/64 * w\n",
    "    left_ankle_y_gt = (64-joint_gt_index[15][0])/64 * h\n",
    "    \n",
    "    right_ankle_x_gt = joint_gt_index[16][1]/64 * w\n",
    "    right_ankle_y_gt = (64-joint_gt_index[16][0])/64 * h\n",
    "    ################################3\n",
    "    nose_x_dt = joint_predict_index[0][1]/64 * w\n",
    "    nose_y_dt = (64-joint_predict_index[0][0])/64 * h\n",
    "\n",
    "    left_shoulder_x_dt = joint_predict_index[5][1]/64 * w\n",
    "    left_shoulder_y_dt = (64-joint_predict_index[5][0])/64 * h\n",
    "    \n",
    "    right_shoulder_x_dt = joint_predict_index[6][1]/64 * w\n",
    "    right_shoulder_y_dt = (64-joint_predict_index[6][0])/64 * h\n",
    "    \n",
    "    neck_x_dt = (left_shoulder_x_dt + right_shoulder_x_dt)/2\n",
    "    neck_y_dt = (left_shoulder_y_dt + right_shoulder_y_dt)/2\n",
    "    \n",
    "    left_elbow_x_dt = joint_predict_index[7][1]/64 * w\n",
    "    left_elbow_y_dt = (64-joint_predict_index[7][0])/64 * h\n",
    "    \n",
    "    right_elbow_x_dt = joint_predict_index[8][1]/64 * w\n",
    "    right_elbow_y_dt = (64-joint_predict_index[8][0])/64 * h\n",
    "    \n",
    "    left_wrist_x_dt = joint_predict_index[9][1]/64 * w\n",
    "    left_wrist_y_dt = (64-joint_predict_index[9][0])/64 * h\n",
    "    \n",
    "    right_wrist_x_dt = joint_predict_index[10][1]/64 * w\n",
    "    right_wrist_y_dt = (64-joint_predict_index[10][0])/64 * h\n",
    "    \n",
    "    left_hip_x_dt = joint_predict_index[11][1]/64 * w\n",
    "    left_hip_y_dt = (64-joint_predict_index[11][0])/64 * h\n",
    "    \n",
    "    right_hip_x_dt = joint_predict_index[12][1]/64 * w\n",
    "    right_hip_y_dt = (64-joint_predict_index[12][0])/64 * h\n",
    "    \n",
    "    hip_x_dt = (left_hip_x_dt + right_hip_x_dt)/2\n",
    "    hip_y_dt = (left_hip_y_dt + right_hip_y_dt)/2\n",
    "\n",
    "    left_knee_x_dt = joint_predict_index[13][1]/64 * w\n",
    "    left_knee_y_dt = (64-joint_predict_index[13][0])/64 * h\n",
    "    \n",
    "    right_knee_x_dt = joint_predict_index[14][1]/64 * w\n",
    "    right_knee_y_dt = (64-joint_predict_index[14][0])/64 * h\n",
    "    \n",
    "    left_ankle_x_dt = joint_predict_index[15][1]/64 * w\n",
    "    left_ankle_y_dt = (64-joint_predict_index[15][0])/64 * h\n",
    "    \n",
    "    right_ankle_x_dt = joint_predict_index[16][1]/64 * w\n",
    "    right_ankle_y_dt = (64-joint_predict_index[16][0])/64 * h\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    " #   nose, neck\n",
    "    if (neck_x_gt != 0 and neck_y_gt != 0) and (nose_x_gt != 0 and nose_y_gt != 0):\n",
    "        x_gt, y_gt = [nose_x_gt, neck_x_gt], [nose_y_gt, neck_y_gt]\n",
    "        x_dt, y_dt = [nose_x_dt, neck_x_dt], [nose_y_dt, neck_y_dt]\n",
    "        plt.plot(x_gt, y_gt, color = 'blue')    \n",
    "        plt.plot(x_dt, y_dt, color = 'red')   \n",
    "        \n",
    "#   left,right shoulder\n",
    "    if (left_shoulder_x_gt != 0 and left_shoulder_y_gt != 0) and (right_shoulder_x_gt != 0 and right_shoulder_y_gt != 0):\n",
    "        x_gt, y_gt = [left_shoulder_x_gt, right_shoulder_x_gt], [left_shoulder_y_gt, right_shoulder_y_gt]\n",
    "        x_dt, y_dt = [left_shoulder_x_dt, right_shoulder_x_dt], [left_shoulder_y_dt, right_shoulder_y_dt]\n",
    "        plt.plot(x_gt, y_gt, color = 'blue')    \n",
    "        plt.plot(x_dt, y_dt, color = 'red')         \n",
    "    \n",
    "#   left shoulder, elbow\n",
    "    if (left_shoulder_x_gt != 0 and left_shoulder_y_gt != 0) and (left_elbow_x_gt != 0 and left_elbow_y_gt != 0):\n",
    "        x_gt, y_gt = [left_shoulder_x_gt, left_elbow_x_gt], [left_shoulder_y_gt, left_elbow_y_gt]\n",
    "        x_dt, y_dt = [left_shoulder_x_dt, left_elbow_x_dt], [left_shoulder_y_dt, left_elbow_y_dt]\n",
    "        plt.plot(x_gt, y_gt, color = 'blue')    \n",
    "        plt.plot(x_dt, y_dt, color = 'red')   \n",
    "        \n",
    "#   right shoulder, elbow\n",
    "    if (right_shoulder_x_gt != 0 and right_shoulder_y_gt != 0) and (right_elbow_x_gt != 0 and right_elbow_y_gt != 0):\n",
    "        x_gt, y_gt = [right_shoulder_x_gt, right_elbow_x_gt], [right_shoulder_y_gt, right_elbow_y_gt]\n",
    "        x_dt, y_dt = [right_shoulder_x_dt, right_elbow_x_dt], [right_shoulder_y_dt, right_elbow_y_dt]\n",
    "        plt.plot(x_gt, y_gt, color = 'blue')    \n",
    "        plt.plot(x_dt, y_dt, color = 'red')   \n",
    "        \n",
    "#   left elbow, wrist\n",
    "    if (left_elbow_x_gt != 0 and left_elbow_y_gt != 0) and (left_wrist_x_gt != 0 and left_wrist_y_gt != 0):\n",
    "        x_gt, y_gt = [left_elbow_x_gt, left_wrist_x_gt], [left_elbow_y_gt, left_wrist_y_gt]\n",
    "        x_dt, y_dt = [left_elbow_x_dt, left_wrist_x_dt], [left_elbow_y_dt, left_wrist_y_dt]\n",
    "        plt.plot(x_gt, y_gt, color = 'blue')    \n",
    "        plt.plot(x_dt, y_dt, color = 'red')   \n",
    "        \n",
    "#   right elbow, wrist\n",
    "    if (right_elbow_x_gt != 0 and right_elbow_y_gt != 0) and (right_wrist_x_gt != 0 and right_wrist_y_gt != 0):\n",
    "        x_gt, y_gt = [right_elbow_x_gt, right_wrist_x_gt], [right_elbow_y_gt, right_wrist_y_gt]\n",
    "        x_dt, y_dt = [right_elbow_x_dt, right_wrist_x_dt], [right_elbow_y_dt, right_wrist_y_dt]\n",
    "        plt.plot(x_gt, y_gt, color = 'blue')    \n",
    "        plt.plot(x_dt, y_dt, color = 'red')  \n",
    "        \n",
    "#   neck, hip\n",
    "    if (neck_x_gt != 0 and neck_y_gt != 0) and (hip_x_gt != 0 and hip_y_gt != 0):\n",
    "        x_gt, y_gt = [neck_x_gt, hip_x_gt], [neck_y_gt, hip_y_gt]\n",
    "        x_dt, y_dt = [neck_x_dt, hip_x_dt], [neck_y_dt, hip_y_dt]\n",
    "        plt.plot(x_gt, y_gt, color = 'blue')    \n",
    "        plt.plot(x_dt, y_dt, color = 'red')          \n",
    "        \n",
    "#   left, right hip\n",
    "    if (left_hip_x_gt != 0 and left_hip_y_gt != 0) and (right_hip_x_gt != 0 and right_hip_y_gt != 0):\n",
    "        x_gt, y_gt = [left_hip_x_gt, right_hip_x_gt], [left_hip_y_gt, right_hip_y_gt]\n",
    "        x_dt, y_dt = [left_hip_x_dt, right_hip_x_dt], [left_hip_y_dt, right_hip_y_dt]\n",
    "        plt.plot(x_gt, y_gt, color = 'blue')    \n",
    "        plt.plot(x_dt, y_dt, color = 'red')          \n",
    "\n",
    "#   left hip, knee\n",
    "    if (left_hip_x_gt != 0 and left_hip_y_gt != 0) and (left_knee_x_gt != 0 and left_knee_y_gt != 0):\n",
    "        x_gt, y_gt = [left_hip_x_gt, left_knee_x_gt], [left_hip_y_gt, left_knee_y_gt]\n",
    "        x_dt, y_dt = [left_hip_x_dt, left_knee_x_dt], [left_hip_y_dt, left_knee_y_dt]\n",
    "        plt.plot(x_gt, y_gt, color = 'blue')    \n",
    "        plt.plot(x_dt, y_dt, color = 'red')      \n",
    "        \n",
    "#   left knee, ankle\n",
    "    if (left_knee_x_gt != 0 and left_knee_y_gt != 0) and (left_ankle_x_gt != 0 and left_ankle_y_gt != 0):\n",
    "        x_gt, y_gt = [left_knee_x_gt, left_ankle_x_gt], [left_knee_y_gt, left_ankle_y_gt]\n",
    "        x_dt, y_dt = [left_knee_x_dt, left_ankle_x_dt], [left_knee_y_dt, left_ankle_y_dt]\n",
    "        plt.plot(x_gt, y_gt, color = 'blue')    \n",
    "        plt.plot(x_dt, y_dt, color = 'red')      \n",
    "\n",
    "#   right hip, knee\n",
    "    if (right_hip_x_gt != 0 and right_hip_y_gt != 0) and (right_knee_x_gt != 0 and right_knee_y_gt != 0):\n",
    "        x_gt, y_gt = [right_hip_x_gt, right_knee_x_gt], [right_hip_y_gt, right_knee_y_gt]\n",
    "        x_dt, y_dt = [right_hip_x_dt, right_knee_x_dt], [right_hip_y_dt, right_knee_y_dt]\n",
    "        plt.plot(x_gt, y_gt, color = 'blue')    \n",
    "        plt.plot(x_dt, y_dt, color = 'red')      \n",
    "        \n",
    "#   right knee, ankle\n",
    "    if (right_knee_x_gt != 0 and right_knee_y_gt != 0) and (right_ankle_x_gt != 0 and right_ankle_y_gt != 0):\n",
    "        x_gt, y_gt = [right_knee_x_gt, right_ankle_x_gt], [right_knee_y_gt, right_ankle_y_gt]\n",
    "        x_dt, y_dt = [right_knee_x_dt, right_ankle_x_dt], [right_knee_y_dt, right_ankle_y_dt]\n",
    "        plt.plot(x_gt, y_gt, color = 'blue')    \n",
    "        plt.plot(x_dt, y_dt, color = 'red')      \n",
    " #######################################3       \n",
    "        \n",
    "        \n",
    "        \n",
    "    plt.savefig(save_dir + '/img' + str(step) +'_joint.png', bbox_inches='tight', pad_inches=0)\n",
    "    \n",
    "    \n",
    "#######    \n",
    "    \n",
    "    \n",
    "    seg_gt = np.argmax(seg_gt,-1)\n",
    "\n",
    "    \n",
    "    seg_pred = np.argmax(seg_pred,-1)\n",
    "    \n",
    "    image = cv2.flip(image, 0)\n",
    "    plt.imsave(save_dir + '/img' + str(step) +'_.png', image)\n",
    "\n",
    " #   plt.imsave(save_dir + '/img' + str(step) +'_joint_gt.png', joint_gt)\n",
    " #   plt.imsave(save_dir + '/img' + str(step) +'_joint_pred.png', joint_pred)\n",
    "    plt.imsave(save_dir + '/img' + str(step) +'_seg_gt.png', seg_gt)\n",
    "    plt.imsave(save_dir + '/img' + str(step) +'_seg_pred.png', seg_pred)\n",
    "    \n",
    "\n",
    "  #  tmp = np.amax(tmp[:,:,1:],-1)\n",
    "  #  tmp *= 255\n",
    "  #  plt.imsave(save_dir + '/img' + str(step) +'_joint_amax.png', tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_cal(point1, point2):\n",
    "    point1_x = point1[0]\n",
    "    point1_y = point1[1]\n",
    "    point2_x = point2[0]\n",
    "    point2_y = point2[1]\n",
    "    \n",
    "    a = point1_x - point2_x\n",
    "    b = point1_y - point2_y\n",
    "    aa = a*a\n",
    "    bb = b*b\n",
    "    cc = aa + bb\n",
    "    return np.sqrt(cc)\n",
    "\n",
    "def PCK_eval(label, pred, pck_rate):\n",
    "    label = label[:,:,:,1:]\n",
    "    pred = pred[:,:,:,1:]\n",
    "    \n",
    "    keypoint_num = 0\n",
    "    anwser_num = 0\n",
    "    \n",
    "    rate = pck_rate\n",
    "\n",
    "    maxindex_list_gt = []\n",
    "    maxindex_list_dt = []\n",
    "    \n",
    "    for i in range(0,17):\n",
    "        yAndx_gt = []\n",
    "\n",
    "        y_gt, x_gt = np.where(label[0,:,:,i] == np.max(label[0,:,:,i])) #(array([], dtype=int64),)\n",
    "        yAndx_gt.append(y_gt[0])\n",
    "        yAndx_gt.append(x_gt[0])\n",
    "        maxindex_list_gt.append(yAndx_gt)\n",
    "\n",
    "        yAndx_dt = []\n",
    "\n",
    "        y_dt, x_dt = np.where(pred[0,:,:,i] == np.max(pred[0,:,:,i]))\n",
    "        yAndx_dt.append(y_dt[0])\n",
    "        yAndx_dt.append(x_dt[0])\n",
    "        maxindex_list_dt.append(yAndx_dt)\n",
    "\n",
    "    torso = euclidean_cal(maxindex_list_gt[5], maxindex_list_gt[12])\n",
    "    \n",
    "    for i in range(0,17):\n",
    "        if i != 1 or i != 2 or i != 3 or i != 4: # without left,right_eye, ear  \n",
    "            if maxindex_list_gt[i] == [0,0]:\n",
    "                continue\n",
    "            else:\n",
    "                keypoint_num += 1\n",
    "                distance = euclidean_cal(maxindex_list_gt[i], maxindex_list_dt[i])\n",
    "                if distance <= torso * rate:\n",
    "                    anwser_num += 1\n",
    "    \n",
    "    return anwser_num/keypoint_num, maxindex_list_gt, maxindex_list_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    tf.reset_default_graph()\n",
    "    ds_test = densepose_agu(path_pose_joint)\n",
    "    \n",
    "    iterator = ds_test.make_one_shot_iterator()\n",
    "    one_element = iterator.get_next()    \n",
    "\n",
    "    img_ph = tf.placeholder(tf.float32, [batch_size, image_resize_w, image_resize_h, 3])\n",
    "    joint_gt_ph = tf.placeholder(tf.float32, [batch_size, net_ouput_w, net_ouput_h, 18])\n",
    "    seg_gt_ph = tf.placeholder(tf.float32, [batch_size, net_ouput_w, net_ouput_h, 15])\n",
    "    \n",
    "    is_train = tf.placeholder(tf.bool, shape=())\n",
    "    \n",
    "    predictions_key, predictions_seg = SHGnet(img_ph, nstack, is_train)\n",
    "        \n",
    "    joint_predict = predictions_key[nstack-1]\n",
    "    seg_predict = predictions_seg[nstack-1]\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IOU_eval(gt_batch, dt_batch):\n",
    "    gt = gt_batch[0]\n",
    "    dt = dt_batch[0]\n",
    "\n",
    "    gt = np.argmax(gt,-1)\n",
    "\n",
    "    \n",
    "    dt = np.argmax(dt,-1)\n",
    "\n",
    "    count = 0\n",
    "    iou = 0\n",
    "    \n",
    "    for i in range(1,15):  # 1 ~ 14\n",
    "        if i == 1 or i ==14:\n",
    "            a = np.zeros([64,64], dtype=np.int32)\n",
    "            b = np.zeros([64,64], dtype=np.int32)\n",
    "            for x in range(64):\n",
    "                for y in range(64):\n",
    "                    if gt[x][y] == i or dt[x][y] == i:\n",
    "                        a[x][y] = 1\n",
    "                    if gt[x][y] == i and dt[x][y] == i:\n",
    "                        b[x][y] = 1\n",
    "            if np.sum(a) != 0:            \n",
    "                iou += np.sum(b)/np.sum(a)\n",
    "                count += 1\n",
    "        \n",
    "    return iou/count\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def IOU_eval(gt_batch, dt_batch):\n",
    "#     gt = gt_batch[0]\n",
    "#     dt = dt_batch[0]\n",
    "\n",
    "#     gt = np.argmax(gt,-1)\n",
    "\n",
    "    \n",
    "#     dt = np.argmax(dt,-1)\n",
    "\n",
    "#     count = 0\n",
    "#     U = 0\n",
    "#     N = 0\n",
    "#     for i in range(1,15):  # 1 ~ 14\n",
    "#         for x in range(64):\n",
    "#             for y in range(64):\n",
    "#                 if gt[x][y] == i or dt[x][y] == i:\n",
    "#                     U += 1\n",
    "#                 if gt[x][y] == i and dt[x][y] == i:\n",
    "#                     N += 1\n",
    "        \n",
    "#     return N/U\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pck@ 0.5\n",
      "INFO:tensorflow:Restoring parameters from ./model/model-180000\n",
      "0.5304713086303564\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "\n",
    "for pck in range(5,6):\n",
    "    pck_rate = pck * 0.1\n",
    "    print('pck@', pck_rate)\n",
    "    for i in range(180000,180001,20000):\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        step = 0\n",
    "\n",
    "        load = save_dir + \"/model-\" + str(i)\n",
    "\n",
    "        saver.restore(sess, load)\n",
    "      #  saver.restore(sess, tf.train.latest_checkpoint(save_dir))\n",
    "\n",
    "        total_pck = 0\n",
    "        total_iou = 0\n",
    "        count = 0\n",
    "        while True:\n",
    "            GT_imgNseg = sess.run(one_element)\n",
    "            joint_predicted, seg_predicted = sess.run([joint_predict, seg_predict], feed_dict={img_ph:GT_imgNseg[0], joint_gt_ph:GT_imgNseg[1], seg_gt_ph:GT_imgNseg[2], is_train:False})\n",
    "\n",
    "            if np.max(GT_imgNseg[1][:,:,:,6]) == 1 and np.max(GT_imgNseg[1][:,:,:,13]) == 1:\n",
    "                count += 1\n",
    "                point, gts, dts = PCK_eval(GT_imgNseg[1], joint_predicted, pck_rate)\n",
    "                \n",
    "                \n",
    "                iou = IOU_eval(GT_imgNseg[2], seg_predicted)\n",
    "                \n",
    "                \n",
    "                total_pck += point\n",
    "                total_iou += iou\n",
    "             #   save_train(vis_test_dir, GT_imgNseg[3], gts, GT_imgNseg[2], dts, seg_predicted, step)\n",
    "\n",
    "\n",
    "            step += 1\n",
    "            if step == test_imgs_num:\n",
    "                break\n",
    "     #   print(total_pck/count)\n",
    "        print(total_iou/count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
